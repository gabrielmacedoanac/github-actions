name: Scrape CSV files

on: [push]

jobs:
  scrape:
    runs-on: ubuntu-latest
    steps:
    - uses: actions/checkout@v2
    - name: Set up Python
      uses: actions/setup-python@v2
      with:
        python-version: 3.8
    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install requests
        pip install beautifulsoup4
    - name: Scrape CSV files
      run: |
        import requests
        from bs4 import BeautifulSoup
        import os

        # Download the HTML of the repository's homepage
        response = requests.get('https://github.com/gabrielmacedoanac/flat-data-anac')
        soup = BeautifulSoup(response.text, 'html.parser')

        # Find all the links to CSV files on the page
        csv_links = []
        for a in soup.find_all('a'):
            if a['href'].endswith('.csv'):
                csv_links.append(a['href'])

        # Download the CSV files and save them to the downloads folder
        for link in csv_links:
            response = requests.get(link)
            file_name = link.split('/')[-1]
            with open(os.path.join('downloads', file_name), 'wb') as f:
                f.write(response.content)
